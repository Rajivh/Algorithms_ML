{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Learning\n",
    "An example of pattern classification in the x-y two dimensional space using a hard limiting function of a Perceptron. We have class A with four patterns given [-3,1],[-2,2],[-1,2],[-1,3] and class B with five patterns [-1,-1],[-2,-2],[-1,-3],[2,-2],[2,1],[0,1]. An output of 1 indicates class A and an output of 0 indicates class B. \n",
    "\n",
    "Weights are initialized (at random) for the input features including a bias weight - so a weight vector of dimension 3 * 1 is created. The sum product of the input and weights is checked - if it is greater than 0, then the output is 1 and 0 otherwise.\n",
    "\n",
    "There occurs an error (+1 or -1) if the calculated output is different from the required output (based on the class label for the corresponding input). \n",
    "All the three weights are adjusted by using the formula: Wnew = Wold + learning_rate * (Target Output - Actual Output) * Input (input is 1 for the bias weight).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_fn(trainingbias,wt,output_data):\n",
    "    activation = np.dot(trainingbias, wt)\n",
    "    activation[activation > 0] = 1\n",
    "    activation[activation <= 0] = 0\n",
    "    error = output_data - activation\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error is  [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "4\n",
      "training_with_bias 1.0 -1.0 -1.0\n",
      "weights before update [[ 0.08680988]\n",
      " [-0.44326123]\n",
      " [-0.15096482]]\n",
      "delta is [[-0.1]\n",
      " [ 0.1]\n",
      " [ 0.1]]\n",
      "weights after update [[-0.01319012]\n",
      " [-0.34326123]\n",
      " [-0.05096482]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "5\n",
      "training_with_bias 1.0 -2.0 -2.0\n",
      "weights before update [[-0.01319012]\n",
      " [-0.34326123]\n",
      " [-0.05096482]]\n",
      "delta is [[-0.1]\n",
      " [ 0.2]\n",
      " [ 0.2]]\n",
      "weights after update [[-0.11319012]\n",
      " [-0.14326123]\n",
      " [ 0.14903518]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-1.]]\n",
      "6\n",
      "training_with_bias 1.0 -1.0 -3.0\n",
      "weights before update [[-0.11319012]\n",
      " [-0.14326123]\n",
      " [ 0.14903518]]\n",
      "delta is [[ 0.]\n",
      " [-0.]\n",
      " [-0.]]\n",
      "weights after update [[-0.11319012]\n",
      " [-0.14326123]\n",
      " [ 0.14903518]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-1.]]\n",
      "error index is [9]\n",
      "9\n",
      "training_with_bias 1.0 0.0 1.0\n",
      "weights before update [[-0.11319012]\n",
      " [-0.14326123]\n",
      " [ 0.14903518]]\n",
      "delta is [[-0.1]\n",
      " [-0. ]\n",
      " [-0.1]]\n",
      "weights after update [[-0.21319012]\n",
      " [-0.14326123]\n",
      " [ 0.04903518]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "error index is []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_data = np.array([[-3,1],[-2,2],[-1,2],[-1,3],[-1,-1],[-2,-2],[-1,-3],[2,-2],[2,1],[0,1]])\n",
    "training_with_bias = np.c_[np.ones(training_data.shape[0]), training_data]\n",
    "output_data = np.array([[1],[1],[1],[1],[0],[0],[0],[0],[0],[0]])\n",
    "\n",
    "output_estimate = np.empty(shape=(output_data.shape))\n",
    "output_estimate1 = np.empty(shape=(output_data.shape))\n",
    "\n",
    "\n",
    "delta = np.empty(shape = (3,1))\n",
    "np.random.seed(100)\n",
    "#weights = np.array([[-0.75],[-1.2],[1.3]])\n",
    "weights = 2*np.random.random((3,1))-1\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "error = activation_fn(training_with_bias, weights, output_data)\n",
    "print(\"error is \",error)\n",
    "\n",
    "error_index = np.where(error!=0)[0]\n",
    "\n",
    "\n",
    "while True:\n",
    "    for i in error_index:\n",
    "        print(i)\n",
    "        delta[0,0] = error[i]*alpha*training_with_bias[i,0]\n",
    "        delta[1,0] = error[i]*alpha*training_with_bias[i,1]\n",
    "        delta[2,0] = error[i]*alpha*training_with_bias[i,2]  \n",
    "        print(\"weights before update\",weights)\n",
    "        print(\"delta is\",delta)\n",
    "        weights += delta\n",
    "        print(\"weights after update\", weights)\n",
    "        error = activation_fn(training_with_bias, weights, output_data)\n",
    "        print(error)\n",
    "        #print(weights)\n",
    "    \n",
    "    error_index = np.where(error!=0)[0]\n",
    "    print(\"error index is\",error_index)\n",
    "    if(len(error_index) ==0):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
